{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST com Tensorflow\n",
    "\n",
    "Resolveremos agora o mesmo problema utilizando diferentes bibliotecas, apenas Numpy; Keras; Tensorflow e Pytorch. A ideia, aqui, é que você tenha uma experiência com cada uma delas para aí poder saber diferencias quando utilizar cada uma na melhor situação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST training images matrix shape\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check MNIST training images matrix data\n",
    "sample_img = mnist.train.images[1].reshape(28, 28)\n",
    "# plot the image\n",
    "plt.imshow(sample_img).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST labels shape\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label data\n",
    "sample_label = mnist.train.labels[1]\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo nossa Rede Neural\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcao da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 193.890698266\n",
      "Epoch: 0002 cost= 44.969539071\n",
      "Epoch: 0003 cost= 27.990002204\n",
      "Epoch: 0004 cost= 19.522133673\n",
      "Epoch: 0005 cost= 14.263742397\n",
      "Epoch: 0006 cost= 10.621454796\n",
      "Epoch: 0007 cost= 7.977389799\n",
      "Epoch: 0008 cost= 5.931062013\n",
      "Epoch: 0009 cost= 4.440852302\n",
      "Epoch: 0010 cost= 3.319992121\n",
      "Epoch: 0011 cost= 2.439423218\n",
      "Epoch: 0012 cost= 1.955467022\n",
      "Epoch: 0013 cost= 1.413456047\n",
      "Epoch: 0014 cost= 1.054891020\n",
      "Epoch: 0015 cost= 0.871857713\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9452\n",
      "Model saved in file: ./tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tera-jul2018]",
   "language": "python",
   "name": "conda-env-tera-jul2018-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
